{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cab-Driver Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kerasNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading keras-2.6.0-py2.py3-none-any.whl (1.3 MB)\n",
      "Installing collected packages: keras\n",
      "Successfully installed keras-2.6.0\n"
     ]
    }
   ],
   "source": [
    "pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\aadi\\anaconda3\\lib\\site-packages (2.3.4)\n",
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.6.0-cp38-cp38-win_amd64.whl (423.2 MB)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in c:\\users\\aadi\\anaconda3\\lib\\site-packages (from tensorflow) (3.7.4.3)\n",
      "Collecting clang~=5.0\n",
      "  Downloading clang-5.0.tar.gz (30 kB)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in c:\\users\\aadi\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.37.0 in c:\\users\\aadi\\anaconda3\\lib\\site-packages (from tensorflow) (1.39.0)\n",
      "Requirement already satisfied: six~=1.15.0 in c:\\users\\aadi\\anaconda3\\lib\\site-packages (from tensorflow) (1.15.0)\n",
      "Collecting gast==0.4.0\n",
      "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Requirement already satisfied: google-pasta~=0.2 in c:\\users\\aadi\\anaconda3\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: wheel~=0.35 in c:\\users\\aadi\\anaconda3\\lib\\site-packages (from tensorflow) (0.36.2)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in c:\\users\\aadi\\anaconda3\\lib\\site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: keras~=2.6 in c:\\users\\aadi\\anaconda3\\lib\\site-packages (from tensorflow) (2.6.0)\n",
      "Requirement already satisfied: tensorboard~=2.6 in c:\\users\\aadi\\anaconda3\\lib\\site-packages (from tensorflow) (2.6.0)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in c:\\users\\aadi\\anaconda3\\lib\\site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in c:\\users\\aadi\\anaconda3\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in c:\\users\\aadi\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.0)\n",
      "Collecting tensorflow-estimator~=2.6\n",
      "  Downloading tensorflow_estimator-2.6.0-py2.py3-none-any.whl (462 kB)\n",
      "Collecting flatbuffers~=1.12.0\n",
      "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
      "Collecting numpy~=1.19.2\n",
      "  Downloading numpy-1.19.5-cp38-cp38-win_amd64.whl (13.3 MB)\n",
      "Requirement already satisfied: absl-py~=0.10 in c:\\users\\aadi\\anaconda3\\lib\\site-packages (from tensorflow) (0.13.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\users\\aadi\\anaconda3\\lib\\site-packages (from tensorflow) (3.17.3)\n",
      "Collecting h5py~=3.1.0\n",
      "  Downloading h5py-3.1.0-cp38-cp38-win_amd64.whl (2.7 MB)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\aadi\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (0.4.5)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\aadi\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\aadi\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (52.0.0.post20210125)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\aadi\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (2.25.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\aadi\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (1.8.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\aadi\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\aadi\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (1.0.1)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in c:\\users\\aadi\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (1.35.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\aadi\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\aadi\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow) (4.2.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\aadi\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow) (4.7.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\aadi\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\aadi\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\aadi\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (1.26.6)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\aadi\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\aadi\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\aadi\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2020.12.5)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\aadi\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (3.1.1)\n",
      "Building wheels for collected packages: clang\n",
      "  Building wheel for clang (setup.py): started\n",
      "  Building wheel for clang (setup.py): finished with status 'done'\n",
      "  Created wheel for clang: filename=clang-5.0-py3-none-any.whl size=30702 sha256=7291e26b42f426d78dcc868fcbf1d7d0112d6c74e52a3f4ba55df5cb5e133f58\n",
      "  Stored in directory: c:\\users\\aadi\\appdata\\local\\pip\\cache\\wheels\\f1\\60\\77\\22b9b5887bd47801796a856f47650d9789c74dc3161a26d608\n",
      "Successfully built clang\n",
      "Installing collected packages: numpy, tensorflow-estimator, h5py, gast, flatbuffers, clang, tensorflow\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.18.5\n",
      "    Uninstalling numpy-1.18.5:\n",
      "      Successfully uninstalled numpy-1.18.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [WinError 5] Access is denied: 'C:\\\\Users\\\\Aadi\\\\anaconda3\\\\Lib\\\\site-packages\\\\~umpy\\\\.libs\\\\libopenblas.PYQHXLVVQ7VESDPUVUADXEVJOBGHJPAY.gfortran-win_amd64.dll'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow-gpu\n",
      "  Downloading tensorflow_gpu-2.6.0-cp38-cp38-win_amd64.whl (423.3 MB)\n",
      "Requirement already satisfied: google-pasta~=0.2 in c:\\users\\aadi\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (0.2.0)\n",
      "Requirement already satisfied: six~=1.15.0 in c:\\users\\aadi\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (1.15.0)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in c:\\users\\aadi\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (1.12.1)\n",
      "Requirement already satisfied: numpy~=1.19.2 in c:\\users\\aadi\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (1.19.5)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in c:\\users\\aadi\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (3.3.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\users\\aadi\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (3.17.3)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.37.0 in c:\\users\\aadi\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (1.39.0)\n",
      "Collecting tensorflow-estimator~=2.6\n",
      "  Using cached tensorflow_estimator-2.6.0-py2.py3-none-any.whl (462 kB)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in c:\\users\\aadi\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (1.1.2)\n",
      "Collecting h5py~=3.1.0\n",
      "  Using cached h5py-3.1.0-cp38-cp38-win_amd64.whl (2.7 MB)\n",
      "Requirement already satisfied: absl-py~=0.10 in c:\\users\\aadi\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (0.13.0)\n",
      "Collecting clang~=5.0\n",
      "  Using cached clang-5.0-py3-none-any.whlNote: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [WinError 5] Access is denied: 'C:\\\\Users\\\\Aadi\\\\anaconda3\\\\Lib\\\\site-packages\\\\~5py\\\\defs.cp38-win_amd64.pyd'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: termcolor~=1.1.0 in c:\\users\\aadi\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (1.1.0)\n",
      "Requirement already satisfied: tensorboard~=2.6 in c:\\users\\aadi\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (2.6.0)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in c:\\users\\aadi\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (3.7.4.3)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in c:\\users\\aadi\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (1.6.3)\n",
      "Collecting flatbuffers~=1.12.0\n",
      "  Using cached flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
      "Collecting gast==0.4.0\n",
      "  Using cached gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Requirement already satisfied: wheel~=0.35 in c:\\users\\aadi\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (0.36.2)\n",
      "Requirement already satisfied: keras~=2.6 in c:\\users\\aadi\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (2.6.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\aadi\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow-gpu) (1.0.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\aadi\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow-gpu) (0.6.1)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in c:\\users\\aadi\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow-gpu) (1.35.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\aadi\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow-gpu) (52.0.0.post20210125)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\aadi\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow-gpu) (3.3.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\aadi\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow-gpu) (2.25.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\aadi\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow-gpu) (1.8.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\aadi\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow-gpu) (0.4.5)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\aadi\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow-gpu) (4.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\aadi\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow-gpu) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\aadi\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow-gpu) (4.7.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\aadi\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow-gpu) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\aadi\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow-gpu) (0.4.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\aadi\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow-gpu) (1.26.6)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\aadi\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow-gpu) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\aadi\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow-gpu) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\aadi\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow-gpu) (2020.12.5)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\aadi\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow-gpu) (3.1.1)\n",
      "Installing collected packages: tensorflow-estimator, h5py, gast, flatbuffers, clang, tensorflow-gpu\n",
      "  Attempting uninstall: tensorflow-estimator\n",
      "    Found existing installation: tensorflow-estimator 2.3.0\n",
      "    Uninstalling tensorflow-estimator-2.3.0:\n",
      "      Successfully uninstalled tensorflow-estimator-2.3.0\n",
      "  Attempting uninstall: h5py\n",
      "    Found existing installation: h5py 2.10.0\n",
      "    Uninstalling h5py-2.10.0:\n",
      "      Successfully uninstalled h5py-2.10.0\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade tensorflow-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "from collections import deque\n",
    "import collections\n",
    "import pickle\n",
    "\n",
    "# for building DQN model\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# for plotting graphs\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the environment\n",
    "from CabEnvironment import CabDriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = CabDriver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining Time Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the time matrix provided\n",
    "Time_matrix = np.load(\"TM.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[ 0.  0.  0. ...  0.  0.  0.]\n",
      "   [ 0.  0.  0. ...  0.  0.  0.]\n",
      "   [ 0.  0.  0. ...  0.  0.  0.]\n",
      "   ...\n",
      "   [ 0.  0.  0. ...  0.  0.  0.]\n",
      "   [ 0.  0.  0. ...  0.  0.  0.]\n",
      "   [ 0.  0.  0. ...  0.  0.  0.]]\n",
      "\n",
      "  [[ 2.  3.  3. ...  7.  0.  6.]\n",
      "   [ 2.  3.  3. ...  7.  0.  6.]\n",
      "   [ 2.  3.  3. ...  7.  0.  6.]\n",
      "   ...\n",
      "   [ 2.  3.  6. ...  7.  4.  2.]\n",
      "   [ 2.  3.  6. ...  7.  4.  2.]\n",
      "   [ 2.  3.  6. ...  7.  4.  2.]]\n",
      "\n",
      "  [[ 2.  6.  5. ...  3.  7.  7.]\n",
      "   [ 2.  6.  5. ...  3.  7.  7.]\n",
      "   [ 2.  6.  5. ...  3.  7.  7.]\n",
      "   ...\n",
      "   [ 6.  2.  8. ...  4.  5.  5.]\n",
      "   [ 6.  2.  8. ...  4.  5.  5.]\n",
      "   [ 6.  2.  8. ...  4.  5.  5.]]\n",
      "\n",
      "  [[10.  6.  8. ...  7.  4.  6.]\n",
      "   [10.  6.  8. ...  7.  4.  6.]\n",
      "   [10.  6.  8. ...  7.  4.  6.]\n",
      "   ...\n",
      "   [ 0.  1.  2. ...  1.  3.  3.]\n",
      "   [ 0.  1.  2. ...  1.  3.  3.]\n",
      "   [ 0.  1.  2. ...  1.  3.  3.]]\n",
      "\n",
      "  [[ 1.  1.  1. ...  1.  1.  1.]\n",
      "   [ 1.  1.  1. ...  1.  1.  1.]\n",
      "   [ 1.  1.  1. ...  1.  1.  1.]\n",
      "   ...\n",
      "   [ 6.  4.  7. ...  3.  1.  8.]\n",
      "   [ 6.  4.  7. ...  3.  1.  8.]\n",
      "   [ 6.  4.  7. ...  3.  1.  8.]]]\n",
      "\n",
      "\n",
      " [[[ 2.  3.  3. ...  7.  0.  6.]\n",
      "   [ 2.  3.  3. ...  7.  0.  6.]\n",
      "   [ 2.  3.  3. ...  7.  0.  6.]\n",
      "   ...\n",
      "   [ 2.  3.  6. ...  7.  4.  2.]\n",
      "   [ 2.  3.  6. ...  7.  4.  2.]\n",
      "   [ 2.  3.  6. ...  7.  4.  2.]]\n",
      "\n",
      "  [[ 0.  0.  0. ...  0.  0.  0.]\n",
      "   [ 0.  0.  0. ...  0.  0.  0.]\n",
      "   [ 0.  0.  0. ...  0.  0.  0.]\n",
      "   ...\n",
      "   [ 0.  0.  0. ...  0.  0.  0.]\n",
      "   [ 0.  0.  0. ...  0.  0.  0.]\n",
      "   [ 0.  0.  0. ...  0.  0.  0.]]\n",
      "\n",
      "  [[ 5.  6.  5. ...  7.  9.  7.]\n",
      "   [ 5.  6.  5. ...  7.  9.  7.]\n",
      "   [ 5.  6.  5. ...  7.  9.  7.]\n",
      "   ...\n",
      "   [ 5. 11.  7. ... 10.  6.  8.]\n",
      "   [ 5. 11.  7. ... 10.  6.  8.]\n",
      "   [ 5. 11.  7. ... 10.  6.  8.]]\n",
      "\n",
      "  [[ 5.  6.  5. ...  5.  4.  4.]\n",
      "   [ 5.  6.  5. ...  5.  4.  4.]\n",
      "   [ 5.  6.  5. ...  5.  4.  4.]\n",
      "   ...\n",
      "   [ 1.  2.  1. ...  3.  2.  0.]\n",
      "   [ 1.  2.  1. ...  3.  2.  0.]\n",
      "   [ 1.  2.  1. ...  3.  2.  0.]]\n",
      "\n",
      "  [[ 4.  1.  4. ...  3.  1.  2.]\n",
      "   [ 4.  1.  4. ...  3.  1.  2.]\n",
      "   [ 4.  1.  4. ...  3.  1.  2.]\n",
      "   ...\n",
      "   [ 4.  0.  3. ...  0.  2.  3.]\n",
      "   [ 4.  0.  3. ...  0.  2.  3.]\n",
      "   [ 4.  0.  3. ...  0.  2.  3.]]]\n",
      "\n",
      "\n",
      " [[[ 2.  6.  5. ...  3.  7.  7.]\n",
      "   [ 2.  6.  5. ...  3.  7.  7.]\n",
      "   [ 2.  6.  5. ...  3.  7.  7.]\n",
      "   ...\n",
      "   [ 6.  2.  8. ...  4.  5.  5.]\n",
      "   [ 6.  2.  8. ...  4.  5.  5.]\n",
      "   [ 6.  2.  8. ...  4.  5.  5.]]\n",
      "\n",
      "  [[ 5.  6.  5. ...  7.  9.  7.]\n",
      "   [ 5.  6.  5. ...  7.  9.  7.]\n",
      "   [ 5.  6.  5. ...  7.  9.  7.]\n",
      "   ...\n",
      "   [ 5. 11.  7. ... 10.  6.  8.]\n",
      "   [ 5. 11.  7. ... 10.  6.  8.]\n",
      "   [ 5. 11.  7. ... 10.  6.  8.]]\n",
      "\n",
      "  [[ 0.  0.  0. ...  0.  0.  0.]\n",
      "   [ 0.  0.  0. ...  0.  0.  0.]\n",
      "   [ 0.  0.  0. ...  0.  0.  0.]\n",
      "   ...\n",
      "   [ 0.  0.  0. ...  0.  0.  0.]\n",
      "   [ 0.  0.  0. ...  0.  0.  0.]\n",
      "   [ 0.  0.  0. ...  0.  0.  0.]]\n",
      "\n",
      "  [[ 6.  6.  3. ...  6. 11.  9.]\n",
      "   [ 6.  6.  3. ...  6. 11.  9.]\n",
      "   [ 6.  6.  3. ...  6. 11.  9.]\n",
      "   ...\n",
      "   [ 3.  4.  4. ...  6.  5.  2.]\n",
      "   [ 3.  4.  4. ...  6.  5.  2.]\n",
      "   [ 3.  4.  4. ...  6.  5.  2.]]\n",
      "\n",
      "  [[ 1.  0.  1. ...  1.  0.  5.]\n",
      "   [ 1.  0.  1. ...  1.  0.  5.]\n",
      "   [ 1.  0.  1. ...  1.  0.  5.]\n",
      "   ...\n",
      "   [ 0.  2.  2. ...  0.  0.  2.]\n",
      "   [ 0.  2.  2. ...  0.  0.  2.]\n",
      "   [ 0.  2.  2. ...  0.  0.  2.]]]\n",
      "\n",
      "\n",
      " [[[10.  6.  8. ...  7.  4.  6.]\n",
      "   [10.  6.  8. ...  7.  4.  6.]\n",
      "   [10.  6.  8. ...  7.  4.  6.]\n",
      "   ...\n",
      "   [ 0.  1.  2. ...  1.  3.  3.]\n",
      "   [ 0.  1.  2. ...  1.  3.  3.]\n",
      "   [ 0.  1.  2. ...  1.  3.  3.]]\n",
      "\n",
      "  [[ 5.  6.  5. ...  5.  4.  4.]\n",
      "   [ 5.  6.  5. ...  5.  4.  4.]\n",
      "   [ 5.  6.  5. ...  5.  4.  4.]\n",
      "   ...\n",
      "   [ 1.  2.  1. ...  3.  2.  0.]\n",
      "   [ 1.  2.  1. ...  3.  2.  0.]\n",
      "   [ 1.  2.  1. ...  3.  2.  0.]]\n",
      "\n",
      "  [[ 6.  6.  3. ...  6. 11.  9.]\n",
      "   [ 6.  6.  3. ...  6. 11.  9.]\n",
      "   [ 6.  6.  3. ...  6. 11.  9.]\n",
      "   ...\n",
      "   [ 3.  4.  4. ...  6.  5.  2.]\n",
      "   [ 3.  4.  4. ...  6.  5.  2.]\n",
      "   [ 3.  4.  4. ...  6.  5.  2.]]\n",
      "\n",
      "  [[ 0.  0.  0. ...  0.  0.  0.]\n",
      "   [ 0.  0.  0. ...  0.  0.  0.]\n",
      "   [ 0.  0.  0. ...  0.  0.  0.]\n",
      "   ...\n",
      "   [ 0.  0.  0. ...  0.  0.  0.]\n",
      "   [ 0.  0.  0. ...  0.  0.  0.]\n",
      "   [ 0.  0.  0. ...  0.  0.  0.]]\n",
      "\n",
      "  [[ 2.  5.  1. ...  3.  2.  2.]\n",
      "   [ 2.  5.  1. ...  3.  2.  2.]\n",
      "   [ 2.  5.  1. ...  3.  2.  2.]\n",
      "   ...\n",
      "   [ 5.  2.  4. ...  4.  6.  3.]\n",
      "   [ 5.  2.  4. ...  4.  6.  3.]\n",
      "   [ 5.  2.  4. ...  4.  6.  3.]]]\n",
      "\n",
      "\n",
      " [[[ 1.  1.  1. ...  1.  1.  1.]\n",
      "   [ 1.  1.  1. ...  1.  1.  1.]\n",
      "   [ 1.  1.  1. ...  1.  1.  1.]\n",
      "   ...\n",
      "   [ 6.  4.  7. ...  3.  1.  8.]\n",
      "   [ 6.  4.  7. ...  3.  1.  8.]\n",
      "   [ 6.  4.  7. ...  3.  1.  8.]]\n",
      "\n",
      "  [[ 4.  1.  4. ...  3.  1.  2.]\n",
      "   [ 4.  1.  4. ...  3.  1.  2.]\n",
      "   [ 4.  1.  4. ...  3.  1.  2.]\n",
      "   ...\n",
      "   [ 4.  0.  3. ...  0.  2.  3.]\n",
      "   [ 4.  0.  3. ...  0.  2.  3.]\n",
      "   [ 4.  0.  3. ...  0.  2.  3.]]\n",
      "\n",
      "  [[ 1.  0.  1. ...  1.  0.  5.]\n",
      "   [ 1.  0.  1. ...  1.  0.  5.]\n",
      "   [ 1.  0.  1. ...  1.  0.  5.]\n",
      "   ...\n",
      "   [ 0.  2.  2. ...  0.  0.  2.]\n",
      "   [ 0.  2.  2. ...  0.  0.  2.]\n",
      "   [ 0.  2.  2. ...  0.  0.  2.]]\n",
      "\n",
      "  [[ 2.  5.  1. ...  3.  2.  2.]\n",
      "   [ 2.  5.  1. ...  3.  2.  2.]\n",
      "   [ 2.  5.  1. ...  3.  2.  2.]\n",
      "   ...\n",
      "   [ 5.  2.  4. ...  4.  6.  3.]\n",
      "   [ 5.  2.  4. ...  4.  6.  3.]\n",
      "   [ 5.  2.  4. ...  4.  6.  3.]]\n",
      "\n",
      "  [[ 0.  0.  0. ...  0.  0.  0.]\n",
      "   [ 0.  0.  0. ...  0.  0.  0.]\n",
      "   [ 0.  0.  0. ...  0.  0.  0.]\n",
      "   ...\n",
      "   [ 0.  0.  0. ...  0.  0.  0.]\n",
      "   [ 0.  0.  0. ...  0.  0.  0.]\n",
      "   [ 0.  0.  0. ...  0.  0.  0.]]]]\n"
     ]
    }
   ],
   "source": [
    "print(Time_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.0\n",
      "0.0\n",
      "3.0542857142857143\n",
      "7.93705306122449\n"
     ]
    }
   ],
   "source": [
    "print(Time_matrix.max())\n",
    "print(Time_matrix.min())\n",
    "print(Time_matrix.mean())\n",
    "print(Time_matrix.var())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tracking the state-action pairs for checking convergence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining a function to save the Q-dictionary as a pickle file\n",
    "def save_obj(obj, name ):\n",
    "    with open(name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agent Class\n",
    "\n",
    "If you are using this framework, you need to fill the following to complete the following code block:\n",
    "1. State and Action Size\n",
    "2. Hyperparameters\n",
    "3. Create a neural-network model in function 'build_model()'\n",
    "4. Define epsilon-greedy strategy in function 'get_action()'\n",
    "5. Complete the function 'append_sample()'. This function appends the recent experience tuple <state, action, reward, new-state> to the memory\n",
    "6. Complete the 'train_model()' function with following logic:\n",
    "   - If the memory size is greater than mini-batch size, you randomly sample experiences from memory as per the mini-batch size and do the following:\n",
    "      - Initialise your input and output batch for training the model\n",
    "      - Calculate the target Q value for each sample: reward + gamma*max(Q(s'a,))\n",
    "      - Get Q(s', a) values from the last trained model\n",
    "      - Update the input batch as your encoded state and output batch as your Q-values\n",
    "      - Then fit your DQN model using the updated input and output batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNAgent:\n",
    "    def __init__(self, state_size, action_size):\n",
    "        # Define size of state and action\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "\n",
    "        # Write here: Specify you hyper parameters for the DQN\n",
    "        self.discount_factor = .99\n",
    "        self.learning_rate = .001\n",
    "        self.epsilon = 1\n",
    "        self.epsilon_max = 1\n",
    "        self.epsilon_decay = .999\n",
    "        self.epsilon_min = .01\n",
    "        \n",
    "        self.batch_size = 32        \n",
    "        # create replay memory using deque\n",
    "        self.memory = deque(maxlen=2000)\n",
    "\n",
    "        # create main model and target model\n",
    "        self.model = self.build_model()\n",
    "\n",
    "    # approximate Q function using Neural Network\n",
    "    def build_model(self):\n",
    "        model = Sequential()\n",
    "        # Write your code here: Add layers to your neural nets \n",
    "        \n",
    "        model.add(Dense(32, input_dim=self.state_size, activation='relu', kernel_initializer='he_uniform'))\n",
    "        model.add(Dense(32, activation='relu', kernel_initializer='he_uniform'))\n",
    "        model.add(Dense(32, activation='relu', kernel_initializer='he_uniform'))\n",
    "        \n",
    "        model.add(Dense(self.action_size, activation='relu', kernel_initializer='he_uniform'))             \n",
    "        \n",
    "        model.compile(loss='mse',optimizer=Adam(lr=self.learning_rate))\n",
    "        model.summary\n",
    "        return model\n",
    "\n",
    "\n",
    "\n",
    "    def get_action(self, state, pos_actions):\n",
    "    # Write your code here:\n",
    "    # get action from model using epsilon-greedy policy\n",
    "    # Decay in ε after we generate each sample from the environment       \n",
    "        #print(\"1\")    \n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            ch = random.choice(pos_actions)\n",
    "            #print(\"2\") \n",
    "        else:\n",
    "            q_values = self.model.predict(state)\n",
    "            pos_action_q_values = list(q_values[0][index] for index in pos_actions)\n",
    "            q_value_max = np.max(pos_action_q_values)\n",
    "            ch = np.where(q_values[0] == q_value_max)\n",
    "            ch = choice[0][0]       \n",
    "            print(\"3\") \n",
    "        return ch\n",
    "    def append_sample(self, state, action, reward, next_state, terminal_state):\n",
    "    # Write your code here:\n",
    "    # save sample <s,a,r,s'> to the replay memory    \n",
    "        self.memory.append((state, action, reward, next_state, terminal_state))\n",
    "        \n",
    "    \n",
    "    # pick samples randomly from replay memory (with batch_size) and train the network\n",
    "    def train_model(self):\n",
    "        \n",
    "        if len(self.memory) > self.batch_size:\n",
    "            # Sample batch from the memory\n",
    "            mini_batch = random.sample(self.memory, self.batch_size)\n",
    "            batch_size = min(self.batch_size, len(self.memory))\n",
    "            update_output = np.zeros((self.batch_size, self.state_size)) # write here\n",
    "            update_input = np.zeros((self.batch_size, self.state_size))# write here\n",
    "            \n",
    "            action, reward = [], []\n",
    "            \n",
    "            for i in range(self.batch_size):\n",
    "                state, action, reward, next_state = mini_batch[i]\n",
    "                update_input[i] = mini_batch[i][0]\n",
    "                actions.append(mini_batch[i][1])\n",
    "                rewards.append(mini_batch[i][2])\n",
    "                update_target[i] = mini_batch[i][3]\n",
    "                terminal_states.append(mini_batch[i][4])\n",
    "                \n",
    "                # Write your code from here\n",
    "                # 1. Predict the target from earlier model\n",
    "            target = self.model.predict(update_input)    \n",
    "                \n",
    "                # 2. Get the target for the Q-network\n",
    "            target_qval = self.target_model.predict(update_target)   \n",
    "                \n",
    "                #3. Update your 'update_output' and 'update_input' batch\n",
    "\n",
    "            for i in range(self.batch_size):\n",
    "                if terminal_states[i]:\n",
    "                    target[i][actions[i]] = rewards[i]\n",
    "                else: \n",
    "                    target[i][actions[i]] = rewards[i] + self.discount_factor * np.max(target_qval[i])   \n",
    "                \n",
    "        # 4. Fit your model and track the loss values\n",
    "            self.model.fit(update_input, target, batch_size=self.batch_size, epochs=1, verbose=0)\n",
    "\n",
    "    def save(self, name):\n",
    "        self.model.save(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "Episodes = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DQN block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 0, 0)\n",
      "[(1, 2), (2, 1), (1, 3), (3, 1), (1, 4), (4, 1), (1, 5), (5, 1), (2, 3), (3, 2), (2, 4), (4, 2), (2, 5), (5, 2), (3, 4), (4, 3), (3, 5), (5, 3), (4, 5), (5, 4), (0, 0)] [(1, 0, 0), (1, 0, 1), (1, 0, 2), (1, 0, 3), (1, 0, 4), (1, 0, 5), (1, 0, 6), (1, 1, 0), (1, 1, 1), (1, 1, 2), (1, 1, 3), (1, 1, 4), (1, 1, 5), (1, 1, 6), (1, 2, 0), (1, 2, 1), (1, 2, 2), (1, 2, 3), (1, 2, 4), (1, 2, 5), (1, 2, 6), (1, 3, 0), (1, 3, 1), (1, 3, 2), (1, 3, 3), (1, 3, 4), (1, 3, 5), (1, 3, 6), (1, 4, 0), (1, 4, 1), (1, 4, 2), (1, 4, 3), (1, 4, 4), (1, 4, 5), (1, 4, 6), (1, 5, 0), (1, 5, 1), (1, 5, 2), (1, 5, 3), (1, 5, 4), (1, 5, 5), (1, 5, 6), (1, 6, 0), (1, 6, 1), (1, 6, 2), (1, 6, 3), (1, 6, 4), (1, 6, 5), (1, 6, 6), (1, 7, 0), (1, 7, 1), (1, 7, 2), (1, 7, 3), (1, 7, 4), (1, 7, 5), (1, 7, 6), (1, 8, 0), (1, 8, 1), (1, 8, 2), (1, 8, 3), (1, 8, 4), (1, 8, 5), (1, 8, 6), (1, 9, 0), (1, 9, 1), (1, 9, 2), (1, 9, 3), (1, 9, 4), (1, 9, 5), (1, 9, 6), (1, 10, 0), (1, 10, 1), (1, 10, 2), (1, 10, 3), (1, 10, 4), (1, 10, 5), (1, 10, 6), (1, 11, 0), (1, 11, 1), (1, 11, 2), (1, 11, 3), (1, 11, 4), (1, 11, 5), (1, 11, 6), (1, 12, 0), (1, 12, 1), (1, 12, 2), (1, 12, 3), (1, 12, 4), (1, 12, 5), (1, 12, 6), (1, 13, 0), (1, 13, 1), (1, 13, 2), (1, 13, 3), (1, 13, 4), (1, 13, 5), (1, 13, 6), (1, 14, 0), (1, 14, 1), (1, 14, 2), (1, 14, 3), (1, 14, 4), (1, 14, 5), (1, 14, 6), (1, 15, 0), (1, 15, 1), (1, 15, 2), (1, 15, 3), (1, 15, 4), (1, 15, 5), (1, 15, 6), (1, 16, 0), (1, 16, 1), (1, 16, 2), (1, 16, 3), (1, 16, 4), (1, 16, 5), (1, 16, 6), (1, 17, 0), (1, 17, 1), (1, 17, 2), (1, 17, 3), (1, 17, 4), (1, 17, 5), (1, 17, 6), (1, 18, 0), (1, 18, 1), (1, 18, 2), (1, 18, 3), (1, 18, 4), (1, 18, 5), (1, 18, 6), (1, 19, 0), (1, 19, 1), (1, 19, 2), (1, 19, 3), (1, 19, 4), (1, 19, 5), (1, 19, 6), (1, 20, 0), (1, 20, 1), (1, 20, 2), (1, 20, 3), (1, 20, 4), (1, 20, 5), (1, 20, 6), (1, 21, 0), (1, 21, 1), (1, 21, 2), (1, 21, 3), (1, 21, 4), (1, 21, 5), (1, 21, 6), (1, 22, 0), (1, 22, 1), (1, 22, 2), (1, 22, 3), (1, 22, 4), (1, 22, 5), (1, 22, 6), (1, 23, 0), (1, 23, 1), (1, 23, 2), (1, 23, 3), (1, 23, 4), (1, 23, 5), (1, 23, 6), (2, 0, 0), (2, 0, 1), (2, 0, 2), (2, 0, 3), (2, 0, 4), (2, 0, 5), (2, 0, 6), (2, 1, 0), (2, 1, 1), (2, 1, 2), (2, 1, 3), (2, 1, 4), (2, 1, 5), (2, 1, 6), (2, 2, 0), (2, 2, 1), (2, 2, 2), (2, 2, 3), (2, 2, 4), (2, 2, 5), (2, 2, 6), (2, 3, 0), (2, 3, 1), (2, 3, 2), (2, 3, 3), (2, 3, 4), (2, 3, 5), (2, 3, 6), (2, 4, 0), (2, 4, 1), (2, 4, 2), (2, 4, 3), (2, 4, 4), (2, 4, 5), (2, 4, 6), (2, 5, 0), (2, 5, 1), (2, 5, 2), (2, 5, 3), (2, 5, 4), (2, 5, 5), (2, 5, 6), (2, 6, 0), (2, 6, 1), (2, 6, 2), (2, 6, 3), (2, 6, 4), (2, 6, 5), (2, 6, 6), (2, 7, 0), (2, 7, 1), (2, 7, 2), (2, 7, 3), (2, 7, 4), (2, 7, 5), (2, 7, 6), (2, 8, 0), (2, 8, 1), (2, 8, 2), (2, 8, 3), (2, 8, 4), (2, 8, 5), (2, 8, 6), (2, 9, 0), (2, 9, 1), (2, 9, 2), (2, 9, 3), (2, 9, 4), (2, 9, 5), (2, 9, 6), (2, 10, 0), (2, 10, 1), (2, 10, 2), (2, 10, 3), (2, 10, 4), (2, 10, 5), (2, 10, 6), (2, 11, 0), (2, 11, 1), (2, 11, 2), (2, 11, 3), (2, 11, 4), (2, 11, 5), (2, 11, 6), (2, 12, 0), (2, 12, 1), (2, 12, 2), (2, 12, 3), (2, 12, 4), (2, 12, 5), (2, 12, 6), (2, 13, 0), (2, 13, 1), (2, 13, 2), (2, 13, 3), (2, 13, 4), (2, 13, 5), (2, 13, 6), (2, 14, 0), (2, 14, 1), (2, 14, 2), (2, 14, 3), (2, 14, 4), (2, 14, 5), (2, 14, 6), (2, 15, 0), (2, 15, 1), (2, 15, 2), (2, 15, 3), (2, 15, 4), (2, 15, 5), (2, 15, 6), (2, 16, 0), (2, 16, 1), (2, 16, 2), (2, 16, 3), (2, 16, 4), (2, 16, 5), (2, 16, 6), (2, 17, 0), (2, 17, 1), (2, 17, 2), (2, 17, 3), (2, 17, 4), (2, 17, 5), (2, 17, 6), (2, 18, 0), (2, 18, 1), (2, 18, 2), (2, 18, 3), (2, 18, 4), (2, 18, 5), (2, 18, 6), (2, 19, 0), (2, 19, 1), (2, 19, 2), (2, 19, 3), (2, 19, 4), (2, 19, 5), (2, 19, 6), (2, 20, 0), (2, 20, 1), (2, 20, 2), (2, 20, 3), (2, 20, 4), (2, 20, 5), (2, 20, 6), (2, 21, 0), (2, 21, 1), (2, 21, 2), (2, 21, 3), (2, 21, 4), (2, 21, 5), (2, 21, 6), (2, 22, 0), (2, 22, 1), (2, 22, 2), (2, 22, 3), (2, 22, 4), (2, 22, 5), (2, 22, 6), (2, 23, 0), (2, 23, 1), (2, 23, 2), (2, 23, 3), (2, 23, 4), (2, 23, 5), (2, 23, 6), (3, 0, 0), (3, 0, 1), (3, 0, 2), (3, 0, 3), (3, 0, 4), (3, 0, 5), (3, 0, 6), (3, 1, 0), (3, 1, 1), (3, 1, 2), (3, 1, 3), (3, 1, 4), (3, 1, 5), (3, 1, 6), (3, 2, 0), (3, 2, 1), (3, 2, 2), (3, 2, 3), (3, 2, 4), (3, 2, 5), (3, 2, 6), (3, 3, 0), (3, 3, 1), (3, 3, 2), (3, 3, 3), (3, 3, 4), (3, 3, 5), (3, 3, 6), (3, 4, 0), (3, 4, 1), (3, 4, 2), (3, 4, 3), (3, 4, 4), (3, 4, 5), (3, 4, 6), (3, 5, 0), (3, 5, 1), (3, 5, 2), (3, 5, 3), (3, 5, 4), (3, 5, 5), (3, 5, 6), (3, 6, 0), (3, 6, 1), (3, 6, 2), (3, 6, 3), (3, 6, 4), (3, 6, 5), (3, 6, 6), (3, 7, 0), (3, 7, 1), (3, 7, 2), (3, 7, 3), (3, 7, 4), (3, 7, 5), (3, 7, 6), (3, 8, 0), (3, 8, 1), (3, 8, 2), (3, 8, 3), (3, 8, 4), (3, 8, 5), (3, 8, 6), (3, 9, 0), (3, 9, 1), (3, 9, 2), (3, 9, 3), (3, 9, 4), (3, 9, 5), (3, 9, 6), (3, 10, 0), (3, 10, 1), (3, 10, 2), (3, 10, 3), (3, 10, 4), (3, 10, 5), (3, 10, 6), (3, 11, 0), (3, 11, 1), (3, 11, 2), (3, 11, 3), (3, 11, 4), (3, 11, 5), (3, 11, 6), (3, 12, 0), (3, 12, 1), (3, 12, 2), (3, 12, 3), (3, 12, 4), (3, 12, 5), (3, 12, 6), (3, 13, 0), (3, 13, 1), (3, 13, 2), (3, 13, 3), (3, 13, 4), (3, 13, 5), (3, 13, 6), (3, 14, 0), (3, 14, 1), (3, 14, 2), (3, 14, 3), (3, 14, 4), (3, 14, 5), (3, 14, 6), (3, 15, 0), (3, 15, 1), (3, 15, 2), (3, 15, 3), (3, 15, 4), (3, 15, 5), (3, 15, 6), (3, 16, 0), (3, 16, 1), (3, 16, 2), (3, 16, 3), (3, 16, 4), (3, 16, 5), (3, 16, 6), (3, 17, 0), (3, 17, 1), (3, 17, 2), (3, 17, 3), (3, 17, 4), (3, 17, 5), (3, 17, 6), (3, 18, 0), (3, 18, 1), (3, 18, 2), (3, 18, 3), (3, 18, 4), (3, 18, 5), (3, 18, 6), (3, 19, 0), (3, 19, 1), (3, 19, 2), (3, 19, 3), (3, 19, 4), (3, 19, 5), (3, 19, 6), (3, 20, 0), (3, 20, 1), (3, 20, 2), (3, 20, 3), (3, 20, 4), (3, 20, 5), (3, 20, 6), (3, 21, 0), (3, 21, 1), (3, 21, 2), (3, 21, 3), (3, 21, 4), (3, 21, 5), (3, 21, 6), (3, 22, 0), (3, 22, 1), (3, 22, 2), (3, 22, 3), (3, 22, 4), (3, 22, 5), (3, 22, 6), (3, 23, 0), (3, 23, 1), (3, 23, 2), (3, 23, 3), (3, 23, 4), (3, 23, 5), (3, 23, 6), (4, 0, 0), (4, 0, 1), (4, 0, 2), (4, 0, 3), (4, 0, 4), (4, 0, 5), (4, 0, 6), (4, 1, 0), (4, 1, 1), (4, 1, 2), (4, 1, 3), (4, 1, 4), (4, 1, 5), (4, 1, 6), (4, 2, 0), (4, 2, 1), (4, 2, 2), (4, 2, 3), (4, 2, 4), (4, 2, 5), (4, 2, 6), (4, 3, 0), (4, 3, 1), (4, 3, 2), (4, 3, 3), (4, 3, 4), (4, 3, 5), (4, 3, 6), (4, 4, 0), (4, 4, 1), (4, 4, 2), (4, 4, 3), (4, 4, 4), (4, 4, 5), (4, 4, 6), (4, 5, 0), (4, 5, 1), (4, 5, 2), (4, 5, 3), (4, 5, 4), (4, 5, 5), (4, 5, 6), (4, 6, 0), (4, 6, 1), (4, 6, 2), (4, 6, 3), (4, 6, 4), (4, 6, 5), (4, 6, 6), (4, 7, 0), (4, 7, 1), (4, 7, 2), (4, 7, 3), (4, 7, 4), (4, 7, 5), (4, 7, 6), (4, 8, 0), (4, 8, 1), (4, 8, 2), (4, 8, 3), (4, 8, 4), (4, 8, 5), (4, 8, 6), (4, 9, 0), (4, 9, 1), (4, 9, 2), (4, 9, 3), (4, 9, 4), (4, 9, 5), (4, 9, 6), (4, 10, 0), (4, 10, 1), (4, 10, 2), (4, 10, 3), (4, 10, 4), (4, 10, 5), (4, 10, 6), (4, 11, 0), (4, 11, 1), (4, 11, 2), (4, 11, 3), (4, 11, 4), (4, 11, 5), (4, 11, 6), (4, 12, 0), (4, 12, 1), (4, 12, 2), (4, 12, 3), (4, 12, 4), (4, 12, 5), (4, 12, 6), (4, 13, 0), (4, 13, 1), (4, 13, 2), (4, 13, 3), (4, 13, 4), (4, 13, 5), (4, 13, 6), (4, 14, 0), (4, 14, 1), (4, 14, 2), (4, 14, 3), (4, 14, 4), (4, 14, 5), (4, 14, 6), (4, 15, 0), (4, 15, 1), (4, 15, 2), (4, 15, 3), (4, 15, 4), (4, 15, 5), (4, 15, 6), (4, 16, 0), (4, 16, 1), (4, 16, 2), (4, 16, 3), (4, 16, 4), (4, 16, 5), (4, 16, 6), (4, 17, 0), (4, 17, 1), (4, 17, 2), (4, 17, 3), (4, 17, 4), (4, 17, 5), (4, 17, 6), (4, 18, 0), (4, 18, 1), (4, 18, 2), (4, 18, 3), (4, 18, 4), (4, 18, 5), (4, 18, 6), (4, 19, 0), (4, 19, 1), (4, 19, 2), (4, 19, 3), (4, 19, 4), (4, 19, 5), (4, 19, 6), (4, 20, 0), (4, 20, 1), (4, 20, 2), (4, 20, 3), (4, 20, 4), (4, 20, 5), (4, 20, 6), (4, 21, 0), (4, 21, 1), (4, 21, 2), (4, 21, 3), (4, 21, 4), (4, 21, 5), (4, 21, 6), (4, 22, 0), (4, 22, 1), (4, 22, 2), (4, 22, 3), (4, 22, 4), (4, 22, 5), (4, 22, 6), (4, 23, 0), (4, 23, 1), (4, 23, 2), (4, 23, 3), (4, 23, 4), (4, 23, 5), (4, 23, 6), (5, 0, 0), (5, 0, 1), (5, 0, 2), (5, 0, 3), (5, 0, 4), (5, 0, 5), (5, 0, 6), (5, 1, 0), (5, 1, 1), (5, 1, 2), (5, 1, 3), (5, 1, 4), (5, 1, 5), (5, 1, 6), (5, 2, 0), (5, 2, 1), (5, 2, 2), (5, 2, 3), (5, 2, 4), (5, 2, 5), (5, 2, 6), (5, 3, 0), (5, 3, 1), (5, 3, 2), (5, 3, 3), (5, 3, 4), (5, 3, 5), (5, 3, 6), (5, 4, 0), (5, 4, 1), (5, 4, 2), (5, 4, 3), (5, 4, 4), (5, 4, 5), (5, 4, 6), (5, 5, 0), (5, 5, 1), (5, 5, 2), (5, 5, 3), (5, 5, 4), (5, 5, 5), (5, 5, 6), (5, 6, 0), (5, 6, 1), (5, 6, 2), (5, 6, 3), (5, 6, 4), (5, 6, 5), (5, 6, 6), (5, 7, 0), (5, 7, 1), (5, 7, 2), (5, 7, 3), (5, 7, 4), (5, 7, 5), (5, 7, 6), (5, 8, 0), (5, 8, 1), (5, 8, 2), (5, 8, 3), (5, 8, 4), (5, 8, 5), (5, 8, 6), (5, 9, 0), (5, 9, 1), (5, 9, 2), (5, 9, 3), (5, 9, 4), (5, 9, 5), (5, 9, 6), (5, 10, 0), (5, 10, 1), (5, 10, 2), (5, 10, 3), (5, 10, 4), (5, 10, 5), (5, 10, 6), (5, 11, 0), (5, 11, 1), (5, 11, 2), (5, 11, 3), (5, 11, 4), (5, 11, 5), (5, 11, 6), (5, 12, 0), (5, 12, 1), (5, 12, 2), (5, 12, 3), (5, 12, 4), (5, 12, 5), (5, 12, 6), (5, 13, 0), (5, 13, 1), (5, 13, 2), (5, 13, 3), (5, 13, 4), (5, 13, 5), (5, 13, 6), (5, 14, 0), (5, 14, 1), (5, 14, 2), (5, 14, 3), (5, 14, 4), (5, 14, 5), (5, 14, 6), (5, 15, 0), (5, 15, 1), (5, 15, 2), (5, 15, 3), (5, 15, 4), (5, 15, 5), (5, 15, 6), (5, 16, 0), (5, 16, 1), (5, 16, 2), (5, 16, 3), (5, 16, 4), (5, 16, 5), (5, 16, 6), (5, 17, 0), (5, 17, 1), (5, 17, 2), (5, 17, 3), (5, 17, 4), (5, 17, 5), (5, 17, 6), (5, 18, 0), (5, 18, 1), (5, 18, 2), (5, 18, 3), (5, 18, 4), (5, 18, 5), (5, 18, 6), (5, 19, 0), (5, 19, 1), (5, 19, 2), (5, 19, 3), (5, 19, 4), (5, 19, 5), (5, 19, 6), (5, 20, 0), (5, 20, 1), (5, 20, 2), (5, 20, 3), (5, 20, 4), (5, 20, 5), (5, 20, 6), (5, 21, 0), (5, 21, 1), (5, 21, 2), (5, 21, 3), (5, 21, 4), (5, 21, 5), (5, 21, 6), (5, 22, 0), (5, 22, 1), (5, 22, 2), (5, 22, 3), (5, 22, 4), (5, 22, 5), (5, 22, 6), (5, 23, 0), (5, 23, 1), (5, 23, 2), (5, 23, 3), (5, 23, 4), (5, 23, 5), (5, 23, 6)] (2, 0, 0)\n",
      "36 21\n"
     ]
    }
   ],
   "source": [
    "scores, episodes = [], []\n",
    "\n",
    "m = 5 # number of cities, ranges from 1 ..... m\n",
    "t = 24 # number of hours, ranges from 0 .... t-1\n",
    "d = 7  # number of days, ranges from 0 ... d-1\n",
    "C = 5 # Per hour fuel and other costs\n",
    "R = 9 # per hour revenue from a passenger\n",
    "\n",
    "state = env.state_init\n",
    "print(state)\n",
    "\n",
    "action_space, state_space, state = env.reset()\n",
    "\n",
    "print(action_space, state_space, state)\n",
    "\n",
    "state_size = m+t+d\n",
    "action_size = len(action_space)\n",
    "\n",
    "\n",
    "print(state_size,action_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 5 is out of bounds for axis 0 with size 5",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-77-2a7407d81691>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;31m#print(env.action_space)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[1;31m#print(action)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m         \u001b[0mreward\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreward_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTime_matrix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m         \u001b[0mnext_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext_state_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTime_matrix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m         \u001b[0mnext_state_encoded\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate_encod_arch1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnext_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\pooja\\cab driver - deep RL\\RL+Project(Cab-Driver)-Code+Structure\\RL Project(Cab-Driver)-Code Structure\\CabEnvironment.py\u001b[0m in \u001b[0;36mreward_func\u001b[1;34m(self, state, action, Time_matrix)\u001b[0m\n\u001b[0;32m     94\u001b[0m             \u001b[0mreward\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mr_cost\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mc_cost\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mnext_state_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTime_matrix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 5 is out of bounds for axis 0 with size 5"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "num_episodes = 1000\n",
    "for episode in range(num_episodes):\n",
    "\n",
    "    # Write code here\n",
    "    terminal_state = False\n",
    "    score = 0\n",
    "    reward = False\n",
    "    \n",
    "    # Call the environment\n",
    "    env = CabDriver()\n",
    "    # Call all the initialised variables of the environment\n",
    "    action_space, state_space, state = env.reset()\n",
    "    initial_state = env.state_init\n",
    "    #Call the DQN agent\n",
    "    agent = DQNAgent(action_size=action_size, state_size=state_size)\n",
    "    \n",
    "  \n",
    "    \n",
    "    while not terminal_state:\n",
    "        \n",
    "        # Write your code here\n",
    "        # 1. Pick epsilon-greedy action from possible actions for the current state\n",
    "        # 2. Evaluate your reward and next state\n",
    "        # 3. Append the experience to the memory\n",
    "        # 4. Train the model by calling function agent.train_model\n",
    "        # 5. Keep a track of rewards, Q-values, loss\n",
    "        \n",
    "        \n",
    "        \n",
    "        possible_actions, action_list = env.requests(state)\n",
    "        \n",
    "        state_encoded = env.state_encod_arch1(state)\n",
    "        \n",
    "        #print(possible_actions)\n",
    "        #print(state_encoded)\n",
    "        \n",
    "        \n",
    "        action = agent.get_action(state_encoded, possible_actions)\n",
    "        #print(possible_actions)\n",
    "        #print(state)\n",
    "        #print(env.action_space[action])\n",
    "        #print(env.action_space)\n",
    "        #print(action)\n",
    "        reward = env.reward_func(state, env.action_space[action], Time_matrix)\n",
    "        next_state = env.next_state_func(state, env.action_space[action], Time_matrix)\n",
    "        next_state_encoded = env.state_encod_arch1(next_state)\n",
    "        next_state_encoded = np.reshape(next_state_encoded, [1, state_size])        \n",
    "        agent.append_sample(state_encoded, action, reward, next_state_encoded, terminal_state)       \n",
    "        \n",
    "        agent.train_model()        \n",
    "        score += reward\n",
    "        state_encoded = next_state_encoded\n",
    "        scores.append(score)\n",
    "        \n",
    "        agent.epsilon = (1 - 0.00001) * np.exp(agent.epsilon_decay * episode)    \n",
    "    \n",
    "    if (episode + 1) % 100 == 0:\n",
    "        print(\"Episode:\", episode + 1, \"  score:\", score, \"  memory length:\", len(agent.memory), \"  epsilon:\", agent.epsilon)\n",
    "        pylab.plot(episodes, scores)\n",
    "        pylab.savefig(\"model\" + pd.datetime.now().hour + pd.datetime.now().minute + \".png\")\n",
    "        agent.save(\"model\" + pd.datetime.now().hour + pd.datetime.now().minute  + \".h5\")\n",
    "        save_obj(agent.self.model.get_weights(), \"cabdriver\" + pd.datetime.now().hour + pd.datetime.now().minute)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tracking Convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (0,) and (24,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-52-9ae61c16c597>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepisodes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[1;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2838\u001b[0m \u001b[1;33m@\u001b[0m\u001b[0m_copy_docstring_and_deprecators\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mAxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2839\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscalex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscaley\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2840\u001b[1;33m     return gca().plot(\n\u001b[0m\u001b[0;32m   2841\u001b[0m         \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscalex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscalex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscaley\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscaley\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2842\u001b[0m         **({\"data\": data} if data is not None else {}), **kwargs)\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\axes\\_axes.py\u001b[0m in \u001b[0;36mplot\u001b[1;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1741\u001b[0m         \"\"\"\n\u001b[0;32m   1742\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1743\u001b[1;33m         \u001b[0mlines\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1744\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1745\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m    271\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    272\u001b[0m                 \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 273\u001b[1;33m             \u001b[1;32myield\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    274\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    275\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_next_color\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[1;34m(self, tup, kwargs)\u001b[0m\n\u001b[0;32m    397\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    398\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 399\u001b[1;33m             raise ValueError(f\"x and y must have same first dimension, but \"\n\u001b[0m\u001b[0;32m    400\u001b[0m                              f\"have shapes {x.shape} and {y.shape}\")\n\u001b[0;32m    401\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (0,) and (24,)"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(episodes, scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Epsilon-decay sample function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Try building a similar epsilon-decay function for your model.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = np.arange(0,10000)\n",
    "epsilon = []\n",
    "for i in range(0,10000):\n",
    "    epsilon.append(0 + (1 - 0) * np.exp(-0.0009*i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(time, epsilon)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
